# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k0_QFplL9ofGIKINRRQY1uyD8msdY-Jq
"""



import pandas as pd
import numpy as np
import tensorflow as tf
import matplotlib as plt
import os

train=pd.read_csv("/content/iomtdosnorm.csv",skipinitialspace=True, low_memory=False)

import numpy as np
train.replace([np.inf, -np.inf], np.nan, inplace=True)
train=train.dropna()

train.drop(['label'], axis=1, inplace=True)

import pandas as pd

# Assuming 'train' is your DataFrame and 'Label' is your target variable
correlations = train.corr()['attack'].drop('attack')  # Drop target variable itself
correlations = correlations.abs().sort_values(ascending=False)  # Sort by absolute value

top_features = correlations.head(36).index  # Select top 4 features
selected_data = train[top_features]  # Create a new DataFrame with selected features

y=train['attack']
# Convert categorical labels to numerical using LabelEncoder

#y_train=y_train.astype(float)

#X=train[significant_features]
#X=train.drop('attack', axis=1)
X=train[top_features]

from sklearn.model_selection import train_test_split
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

from imblearn.over_sampling import SMOTE
def balance_dataset(X, y):
    smote = SMOTE(random_state=42)
    X_balanced, y_balanced = smote.fit_resample(X, y)

    return X_balanced, y_balanced
(X_train,y_train)=balance_dataset(X_train, y_train)

X_train=X_train.astype('uint8')
X_val=X_val.astype('uint8')

import math
sh=math.sqrt((X_train.shape[1]))

sh=int(sh)
sh

image=X_train.values.reshape(-1, sh,sh)

from PIL import Image
import numpy as np # Import numpy for array operations

os.chdir('/content/')
if not os.path.exists("download1"):
    os.makedirs("download1")

# Change the current working directory
os.chdir("download1")

for i in range(X_train.shape[0]):
    if y_train.iloc[i]==0:
      #image=X_train.values.reshape(-1, 3,3)

# Calculate global min and max from the entire 'image' array for consistent scaling
      min_val = image.min()
      max_val = image.max()
    # Scale the current 3x3 image array to 0-255
    # Handle the case where max_val == min_val to avoid division by zero
      if max_val == min_val:
        # If all values are the same, create a black image
        scaled_img_array = np.zeros_like(image[i], dtype=np.uint8)
      else:
        scaled_img_array = ((image[i] - min_val) / (max_val - min_val)) * 255

    # Convert to unsigned 8-bit integer type
      uint8_img_array = scaled_img_array.astype(np.uint8)


    # Create PIL Image from the uint8 array
      img = Image.fromarray(uint8_img_array)
      img.save(f'Normal.{i}.jpg',"JPEG")

from PIL import Image
import numpy as np # Import numpy for array operations

os.chdir('/content/')

if not os.path.exists("download1"):
    os.makedirs("download1")

# Change the current working directory
os.chdir("download1")

for i in range(X_train.shape[0]):
    if y_train.iloc[i]==1:
      #image=X_train.values.reshape(-1,3,3)

# Calculate global min and max from the entire 'image' array for consistent scaling
      min_val = image.min()
      max_val = image.max()
    # Scale the current 3x3 image array to 0-255
    # Handle the case where max_val == min_val to avoid division by zero
      if max_val == min_val:
        # If all values are the same, create a black image
        scaled_img_array = np.zeros_like(image[i], dtype=np.uint8)
      else:
        scaled_img_array = ((image[i] - min_val) / (max_val - min_val)) * 255

    # Convert to unsigned 8-bit integer type
      uint8_img_array = scaled_img_array.astype(np.uint8)


    # Create PIL Image from the uint8 array
      img = Image.fromarray(uint8_img_array)
      img.save(f'Attack.{i}.jpg',"JPEG")

rm -rf /content/download2

test=pd.read_csv("/content/iomtarpspoofnorm.csv", skipinitialspace=True, low_memory=False)

import numpy as np
test.replace([np.inf, -np.inf], np.nan, inplace=True)
test=test.dropna()

import pandas as pd
from sklearn.preprocessing import LabelEncoder

# Identify categorical columns
categorical_cols = test.select_dtypes(include=['object']).columns

# Apply Label Encoding to each categorical column
for col in categorical_cols:
    le = LabelEncoder()
    test[col] = le.fit_transform(test[col])

y_test=test['attack']
# Convert categorical labels to numerical using LabelEncoder

#y_train=y_train.astype(float)

X_test=test[top_features]

from imblearn.over_sampling import SMOTE
def balance_dataset(X, y):
    smote = SMOTE(random_state=42)
    X_balanced, y_balanced = smote.fit_resample(X, y)

    return X_balanced, y_balanced
(X_test,y_test)=balance_dataset(X_test, y_test)

image=X_val.values.reshape(-1, sh,sh)

from PIL import Image
import numpy as np # Import numpy for array operations

os.chdir('/content/')
if not os.path.exists("download1val"):
    os.makedirs("download1val")

# Change the current working directory
os.chdir("download1val")

for i in range(X_val.shape[0]):
    if y_val.iloc[i]==0:


# Calculate global min and max from the entire 'image' array for consistent scaling
      min_val = image.min()
      max_val = image.max()
    # Scale the current 3x3 image array to 0-255
    # Handle the case where max_val == min_val to avoid division by zero
      if max_val == min_val:
        # If all values are the same, create a black image
        scaled_img_array = np.zeros_like(image[i], dtype=np.uint8)
      else:
        scaled_img_array = ((image[i] - min_val) / (max_val - min_val)) * 255

    # Convert to unsigned 8-bit integer type
      uint8_img_array = scaled_img_array.astype(np.uint8)


    # Create PIL Image from the uint8 array
      img = Image.fromarray(uint8_img_array)
      img.save(f'Normal.{i}.jpg',"JPEG")

from PIL import Image
import numpy as np # Import numpy for array operations

os.chdir('/content/')

if not os.path.exists("download1val"):
    os.makedirs("download1val")

# Change the current working directory
os.chdir("download1val")

for i in range(X_val.shape[0]):
    if y_val.iloc[i]==1:
    #  image=X_val.values.reshape(-1, 3,3)

# Calculate global min and max from the entire 'image' array for consistent scaling
      min_val = image.min()
      max_val = image.max()
    # Scale the current 3x3 image array to 0-255
    # Handle the case where max_val == min_val to avoid division by zero
      if max_val == min_val:
        # If all values are the same, create a black image
        scaled_img_array = np.zeros_like(image[i], dtype=np.uint8)
      else:
        scaled_img_array = ((image[i] - min_val) / (max_val - min_val)) * 255

    # Convert to unsigned 8-bit integer type
      uint8_img_array = scaled_img_array.astype(np.uint8)


    # Create PIL Image from the uint8 array
      img = Image.fromarray(uint8_img_array)
      img.save(f'Attack.{i}.jpg',"JPEG")

X_test=X_test.astype('uint8')
image=X_test.values.reshape(-1, sh,sh)

from PIL import Image
import numpy as np # Import numpy for array operations

os.chdir('/content/')
if not os.path.exists("download2"):
    os.makedirs("download2")

# Change the current working directory
os.chdir("download2")

for i in range(X_test.shape[0]):
    if y_test.iloc[i]==0:


# Calculate global min and max from the entire 'image' array for consistent scaling
      min_val = image.min()
      max_val = image.max()
    # Scale the current 3x3 image array to 0-255
    # Handle the case where max_val == min_val to avoid division by zero
      if max_val == min_val:
        # If all values are the same, create a black image
        scaled_img_array = np.zeros_like(image[i], dtype=np.uint8)
      else:
        scaled_img_array = ((image[i] - min_val) / (max_val - min_val)) * 255

    # Convert to unsigned 8-bit integer type
      uint8_img_array = scaled_img_array.astype(np.uint8)


    # Create PIL Image from the uint8 array
      img = Image.fromarray(uint8_img_array)
      img.save(f'Normal.{i}.jpg',"JPEG")

from PIL import Image
import numpy as np # Import numpy for array operations

os.chdir('/content/')

if not os.path.exists("download2"):
    os.makedirs("download2")

# Change the current working directory
os.chdir("download2")

for i in range(X_test.shape[0]):
    if y_test.iloc[i]==1:
      #image=X_test.values.reshape(-1, 3,3)

# Calculate global min and max from the entire 'image' array for consistent scaling
      min_val = image.min()
      max_val = image.max()
    # Scale the current 3x3 image array to 0-255
    # Handle the case where max_val == min_val to avoid division by zero
      if max_val == min_val:
        # If all values are the same, create a black image
        scaled_img_array = np.zeros_like(image[i], dtype=np.uint8)
      else:
        scaled_img_array = ((image[i] - min_val) / (max_val - min_val)) * 255

    # Convert to unsigned 8-bit integer type
      uint8_img_array = scaled_img_array.astype(np.uint8)


    # Create PIL Image from the uint8 array
      img = Image.fromarray(uint8_img_array)
      img.save(f'Attack.{i}.jpg',"JPEG")

#test2
os.chdir("/content/")

train_img_dir_n = "/content/download1"
#train_img_dir_n =train_img_dir_n [:1000]
train_img_paths_n = [os.path.join(train_img_dir_n,filename) for filename in os.listdir(train_img_dir_n)]

import re

train_path_df = pd.DataFrame({
    'path': [],
    'target': []
})

for path in train_img_paths_n:
    pattern = r'Normal'

    match = re.search(pattern, path)

    if match:
        train_path_df = pd.concat([train_path_df, pd.DataFrame({'path': [path], 'target': [0]})], ignore_index=True)
    else:
        train_path_df = pd.concat([train_path_df, pd.DataFrame({'path': [path], 'target': [1]})], ignore_index=True)

test_img_dir_n = "/content/download2/"
#train_img_dir_n =train_img_dir_n [:1000]
test_img_paths_n = [os.path.join(test_img_dir_n,filename) for filename in os.listdir(test_img_dir_n)]

import re

test_path_df = pd.DataFrame({
    'path': [],
    'target': []
})

for path in test_img_paths_n:
    pattern = r'Normal'

    match = re.search(pattern, path)

    if match:
        test_path_df = pd.concat([test_path_df, pd.DataFrame({'path': [path], 'target': [0]})], ignore_index=True)
    else:
        test_path_df = pd.concat([test_path_df, pd.DataFrame({'path': [path], 'target': [1]})], ignore_index=True)

val_img_dir_n = "/content/download1val/"
#train_img_dir_n =train_img_dir_n [:1000]
val_img_paths_n = [os.path.join(val_img_dir_n,filename) for filename in os.listdir(val_img_dir_n)]

import re

val_path_df = pd.DataFrame({
    'path': [],
    'target': []
})

for path in val_img_paths_n:
    pattern = r'Normal'

    match = re.search(pattern, path)

    if match:
        val_path_df = pd.concat([val_path_df, pd.DataFrame({'path': [path], 'target': [0]})], ignore_index=True)
    else:
        val_path_df = pd.concat([val_path_df, pd.DataFrame({'path': [path], 'target': [1]})], ignore_index=True)

from keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator

batch_size = 32 # You can adjust this value

datagen = ImageDataGenerator(
    rescale=1./255,
    #validation_split = .2

)

train_path_df['target'] = train_path_df['target'].astype(str)

batch_size = 64

train_image_generator = datagen.flow_from_dataframe(
    train_path_df,
    x_col='path',
    y_col='target',
    target_size=(75,75),  # Adjust to match your model's input size
    batch_size=batch_size,
    class_mode='binary',  # Change to 'binary' if you have binary classes
    shuffle=True,
    color_mode='rgb',
    #subset='training'
)

val_path_df['target'] = val_path_df['target'].astype(str)

val_image_generator = datagen.flow_from_dataframe(
    val_path_df,
    x_col='path',
    y_col='target',
    target_size=(75,75),  # Adjust to match your model's input size
    batch_size=batch_size,
    class_mode='binary',  # Change to 'binary' if you have binary classes
    shuffle=True,
    color_mode='rgb',
    #subset='validation'
)

test_path_df['target'] = test_path_df['target'].astype(str)

test_image_generator = datagen.flow_from_dataframe(
    test_path_df,
    x_col='path',
    y_col='target',
    target_size=(75,75),  # Adjust to match your model's input size
    batch_size=batch_size,
    class_mode='binary',  # Change to 'binary' if you have binary classes
    shuffle=False,
    color_mode='rgb'
)

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

def create_vit_classifier():
    # Input
    inputs = layers.Input(shape=(image_size, image_size, 3)) # Adjust image_size

    # Augment data.
    #augmented = data_augmentation(inputs)

    # Create patches.
    patches = Patches(patch_size)(inputs)

    # Encode patches.
    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)

    # Define num_heads here or before calling create_vit_classifier
    num_heads = 8  # You can adjust the number of heads as needed


    # Create multiple layers of the Transformer block.
    for _ in range(transformer_layers):
        # Layer normalization 1.
        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)

        # Multi head self attention.
        attention_output = layers.MultiHeadAttention(
            num_heads=num_heads, key_dim=projection_dim, dropout=0.1
        )(x1, x1)

        # Skip connection 1.
        x2 = layers.Add()([attention_output, encoded_patches])

        # Layer normalization 2.
        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)

        # MLP.
        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)

        # Skip connection 2.
        encoded_patches = layers.Add()([x3, x2])

    # Create a [batch_size, projection_dim] tensor.
    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)
    representation = layers.Flatten()(representation)
    representation = layers.Dropout(0.5)(representation)

    # Add MLP.
    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)

    # Classify outputs.
    logits = layers.Dense(num_classes)(features)

    # Create the Keras model.
    model = keras.Model(inputs=inputs, outputs=logits)
    return model

class Patches(layers.Layer):
    def __init__(self, patch_size):
        super(Patches, self).__init__()
        self.patch_size = patch_size

    def call(self, images):
        batch_size = tf.shape(images)[0]  # Get batch size as a tensor
        patches = tf.image.extract_patches(
            images=images,
            sizes=[1, self.patch_size, self.patch_size, 1],
            strides=[1, self.patch_size, self.patch_size, 1],
            rates=[1, 1, 1, 1],
            padding="VALID",
        )
        # Calculate patch_dims dynamically using tf.shape
        patch_dims = tf.shape(patches)[-1]
        # Use tf.reshape with dynamic shapes
        patches = tf.reshape(patches, [batch_size, -1, patch_dims])
        return patches

class PatchEncoder(layers.Layer):
    def __init__(self, num_patches, projection_dim):
        super(PatchEncoder, self).__init__()
        self.num_patches = num_patches
        self.projection = layers.Dense(units=projection_dim)
        self.position_embedding = layers.Embedding(
            input_dim=num_patches, output_dim=projection_dim
        )

    def call(self, patches):
        positions = tf.range(start=0, limit=self.num_patches, delta=1)
        encoded = self.projection(patches) + self.position_embedding(positions)
        return encoded

def mlp(x, hidden_units, dropout_rate):
    for units in hidden_units:
        x = layers.Dense(units, activation=tf.nn.gelu)(x)
        x = layers.Dropout(dropout_rate)(x)
    return x

# Hyperparameters
image_size = 75 # Adjust as needed
patch_size = 16 # Size of the patches to be extracted from the input images
num_patches = (image_size // patch_size) ** 2
projection_dim = 64
transformer_units = [
    projection_dim * 2,
    projection_dim,
] # Size of the transformer layers
transformer_layers = 8
mlp_head_units = [2048, 1024] # Size of the dense layers of the final classifier
num_classes = 1 # Number of classes in your dataset

vit_classifier = create_vit_classifier()
vit_classifier.summary()

from keras.callbacks import EarlyStopping, ReduceLROnPlateau

early_stopping = EarlyStopping(
    monitor="val_loss",
    mode="min",
    verbose=1,
    patience=10,
    restore_best_weights=True # Highly recommended to keep the best version
)

lr_reduce = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=5,
    mode="min",
    verbose=1,
    min_lr=1e-7 # Lowered this to be less than your 3e-4 start
)

call_backs = [early_stopping, lr_reduce]

from keras.callbacks import ModelCheckpoint

# Create the ViT classifier
vit_classifier = create_vit_classifier()

checkpoint_filepath_vit = '/content/vit_best_model.weights.h5'
model_checkpoint_callback_vit = ModelCheckpoint(
    filepath=checkpoint_filepath_vit,
    save_weights_only=True,
    monitor='val_accuracy',
    mode='max',
    save_best_only=True
)

# Combine existing callbacks with the new model checkpoint callback
vit_callbacks = [early_stopping, lr_reduce, model_checkpoint_callback_vit]

# Compile the model
vit_classifier.compile(
    optimizer=tf.keras.optimizers.AdamW(
        learning_rate=3e-4, weight_decay=0.0001
    ),
    loss=keras.losses.BinaryCrossentropy(from_logits=True),
    metrics=[
        keras.metrics.BinaryAccuracy(name="accuracy"),
    ],
)

# Train the model using the generators
history = vit_classifier.fit(
    train_image_generator,
    epochs=100,
    validation_data=val_image_generator,
    callbacks=vit_callbacks
)

from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns


# Evaluate the ViT model on the test dataset
predictions = vit_classifier.predict(test_image_generator)

# Convert predictions to binary labels (0 or 1) using a threshold (e.g., 0.5)
# Since the loss is BinaryCrossentropy(from_logits=True), the output is logits,
# so we apply a sigmoid activation to get probabilities before thresholding.
predicted_probabilities = tf.sigmoid(predictions).numpy()
predicted_labels = (predicted_probabilities > 0.5).astype(int)


# Get the true labels from the test generator
true_labels = test_image_generator.classes

# Calculate and print evaluation metrics
accuracy = accuracy_score(true_labels, predicted_labels)
print("Accuracy:", accuracy)

report = classification_report(true_labels, predicted_labels)
print("Classification Report:\n", report)

roc_auc = roc_auc_score(true_labels, predicted_probabilities) # Use probabilities for ROC AUC
print(f"ROC AUC: {roc_auc}")

# Display the confusion matrix
cm = confusion_matrix(true_labels, predicted_labels)


plt.figure(figsize=(6, 5)) # Adjust figure size as needed
ax = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['Predicted Normal', 'Predicted Attack'],
            yticklabels=['Actual Normal', 'Actual Attack'])

# Make annotations bold
for text in plt.gca().texts:
    text.set_weight('bold')

# Make yticklabels bold
for label in ax.get_yticklabels():
    label.set_fontweight('bold')

# Make xticklabels bold
for label in ax.get_xticklabels():
    label.set_fontweight('bold')

plt.xlabel('Predicted Label', fontsize=12, fontweight='bold')
plt.ylabel('True Label', fontsize=12, fontweight='bold')
#plt.title('Confusion Matrix', fontsize=14, fontweight='bold')
plt.show()

import tensorflow as tf
#inception
from keras.applications.inception_v3 import InceptionV3
inception = InceptionV3(input_shape=(75,75,3), weights='imagenet', include_top=False)
for layer in inception.layers:
    layer.trainable = False
from tensorflow.keras.optimizers import RMSprop,Adam
from tensorflow.keras import layers

x = layers.Flatten()(inception.output)
#x = layers.Dense(128, activation='relu')(x)
#x = layers.Dropout(0.2)(x)

# Add a final sigmoid layer with 1 node for classification output
x = layers.Dense(1, activation='sigmoid')(x)

model = tf.keras.models.Model(inception.input, x)
model.summary()

from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, UpSampling2D, Conv2D, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.models import Sequential

model = Sequential()
# add the pretrained model
model.add(ResNet50(include_top=False, pooling='max', weights='imagenet', input_shape=(75,75,3)))
# add fully connected layer with output
#model.add(Dense(128, activation='relu'))
#model.add(Dropout(0.2))
model.add(Dense(1, activation='sigmoid'))

# set resnet layers not trainable
model.layers[0].trainable=False

#model.build(input_shape=(None, 32,32, 3))
model.summary()

from keras.applications.vgg16 import VGG16

# Form the correct input shape for the model in case the `TARGET_SIZE`
# is not square (e.g. (224, 224)).
INPUT_SHAPE = (75,75, 3)

base_model = VGG16(
    weights='imagenet',  # load weights pretrained on the ImageNet
    include_top=False,  # do not include the ImageNet classifier at the top
    input_shape=INPUT_SHAPE,
    pooling='max'  # add a global max pooling layer after the base model
)

base_model.summary()
import keras
from keras.layers import Dropout, Dense

# Freeze the base model so that only the new top layers are trained.
base_model.trainable = False

num_classes = 1

model = keras.Sequential([
    base_model,
    #Dropout(0.2),
    #Dense(128, activation='relu'),
    # Dense(128, activation='relu'),
    #Dropout(0.2),
    Dense(num_classes, activation='sigmoid')
])

model.summary()

from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
early_stopping = EarlyStopping(monitor="val_loss", mode="min", verbose=1, patience=10,restore_best_weights=True)
lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, mode="min", verbose=1, min_lr=1e-6)
call_backs = [ early_stopping, lr_reduce]

import keras
from tensorflow.keras.metrics import Precision, Recall

checkpoint_filepath = '/content/rtiotdosddos2_12_24.weights.h5'
model_checkpoint_callback = keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_filepath,
    save_weights_only=True,
    monitor='val_accuracy',
    mode='max',
    save_best_only=True)
call_back = [ early_stopping, lr_reduce, model_checkpoint_callback ]

from datetime import datetime
start_time = datetime.now()
model.compile(loss='binary_crossentropy',
              optimizer=keras.optimizers.Adam(learning_rate=0.001),
              metrics=['accuracy', Precision(), Recall()])


history=model.fit(train_image_generator,


                    validation_data=val_image_generator,

                    epochs=100,
                  callbacks=call_back
)
#Train the model
#history=model.fit(train_image_generator,epochs=100,  callbacks=call_backs)

end_time = datetime.now()

# Calculate elapsed time
elapsed_time = end_time - start_time

# Print the elapsed time
print(f"Training time: {elapsed_time}")
# Evaluate the model

print("Evaluating the model on the test set:")

# Evaluate the model on the test_image_generator
loss, accuracy, precision, recall = model.evaluate(test_image_generator)

print(f"Test Loss: {loss:.4f}")
print(f"Test Accuracy: {accuracy:.4f}")
print(f"Test Precision: {precision:.4f}")
print(f"Test Recall: {recall:.4f}")

from sklearn.metrics import accuracy_score, classification_report, roc_auc_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import numpy as np

# Prediction without the optimization loop (using default threshold of 0.5)
model.load_weights('/content/rtiotdosddos2_12_24.weights.h5')
predictions = model.predict(test_image_generator)
true_labels = test_image_generator.labels # Corrected: Use .labels instead of .classes

# Use 0.5 as the implicit threshold
predicted_labels_default = (predictions >= 0.5).astype(int)

# Evaluate performance with the default threshold
default_accuracy = accuracy_score(true_labels, predicted_labels_default)
default_report = classification_report(true_labels, predicted_labels_default)

# Check if there's more than one class for ROC AUC calculation
if len(np.unique(true_labels)) > 1:
    roc_auc = roc_auc_score(true_labels, predictions)
    print(f"ROC AUC: {roc_auc}")
else:
    print("ROC AUC cannot be calculated for a single class dataset.")

print(f"Default Accuracy (Threshold 0.5): {default_accuracy}")
print("Default Classification Report:\n", default_report)

# Generate the confusion matrix
cm = confusion_matrix(true_labels, predicted_labels_default)

# Display the confusion matrix with requested formatting
disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                              display_labels=['Normal', 'Attack'])

# Plot with blue colormap and bold text
disp.plot(cmap=plt.cm.Blues)
plt.title('**Confusion Matrix**', fontweight='bold')
plt.xlabel('**Predicted Label**', fontweight='bold')
plt.ylabel('**True Label**', fontweight='bold')

# Make the numbers inside the matrix bold
for text in disp.text_.ravel():
    text.set_fontweight('bold')

# Make the display_labels ('Normal', 'Attack') bold
for label in disp.ax_.get_xticklabels():
    label.set_fontweight('bold')
for label in disp.ax_.get_yticklabels():
    label.set_fontweight('bold')

plt.show()

import numpy as np
from sklearn.metrics import roc_curve, accuracy_score, classification_report
model.load_weights('/content/rtiotdosddos2_12_24.weights.h5')
#predictions = model.predict(test_image_generator)
true_labels = test_image_generator.labels # Corrected: Use .labels instead of .classes


# Ensure predictions are flattened if they are a 2D array (e.g., from model.predict)
predictions_flat = predictions.flatten()

# Calculate FPR, TPR, and thresholds from the ROC curve
fpr, tpr, thresholds = roc_curve(true_labels, predictions_flat)

# Calculate Youden's J statistic for each threshold
youden_j = tpr - fpr

# Find the optimal threshold (the one that maximizes Youden's J)
optimal_idx = np.argmax(youden_j)
optimal_threshold = thresholds[optimal_idx]

# Get the corresponding TPR and FPR at the optimal threshold
optimal_tpr = tpr[optimal_idx]
optimal_fpr = fpr[optimal_idx]

# Predict labels using the optimal threshold
predicted_labels_optimal = (predictions_flat >= optimal_threshold).astype(int)

# Calculate accuracy at the optimal threshold
accuracy_optimal = accuracy_score(true_labels, predicted_labels_optimal)

print(f"Optimal Threshold (Youden's J): {optimal_threshold:.4f}")
print(f"  True Positive Rate (Sensitivity): {optimal_tpr:.4f}")
print(f"  False Positive Rate (1 - Specificity): {optimal_fpr:.4f}")
print(f"  Accuracy at Optimal Threshold: {accuracy_optimal:.4f}")
print("\nClassification Report at Optimal Threshold:\n", classification_report(true_labels, predicted_labels_optimal))

import torch
import cv2
import numpy as np
import matplotlib.pyplot as plt
from torchvision import models, transforms
from PIL import Image

# Load InceptionV3 model
model = models.inception_v3(pretrained=True, aux_logits=True) # aux_logits for pretrained inception
model.eval()

# Hook the gradients
gradients = []

def save_gradient(grad):
    gradients.append(grad)

# Choose the target convolutional layer for Grad-CAM in InceptionV3
target_layer = model.Mixed_7c # A deep convolutional block in InceptionV3

# Register forward hook
activations = []

def forward_hook(module, input, output):
    activations.append(output)
    output.register_hook(save_gradient)

target_layer.register_forward_hook(forward_hook)

# Load and preprocess the image
img = Image.open("/content/download2/Normal.1744.jpg").convert('RGB')

transform = transforms.Compose([
    transforms.Resize((299, 299)), # InceptionV3 typically expects 299x299
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # ImageNet normalization
])
input_tensor = transform(img).unsqueeze(0)

# Forward pass
output = model(input_tensor) # For InceptionV3, output is usually a tuple for training with aux_logits, but for eval, it's just the main output

# If model is in eval mode and aux_logits=True, output might still be a tuple for old torchvision versions.
# Ensure we get the main output for classification.
if isinstance(output, tuple):
    output = output[0]

class_idx = torch.argmax(output)

# Backward pass for the target class
model.zero_grad()
output[0, class_idx].backward()

# Get activations and gradients
act = activations[0].squeeze().detach().cpu().numpy()
grad = gradients[0].squeeze().detach().cpu().numpy()

# Compute weights
weights = np.mean(grad, axis=(1, 2))

# Compute Grad-CAM
cam = np.zeros(act.shape[1:], dtype=np.float32)
for i, w in enumerate(weights):
    cam += w * act[i]

cam = np.maximum(cam, 0)
cam = cv2.resize(cam, (299, 299)) # Resize to InceptionV3 input size
cam = cam - cam.min()
cam = cam / cam.max()

# Overlay CAM on image
img_np = np.array(img.resize((299, 299))) / 255.0 # Resize original image
heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)
overlay = 0.4 * heatmap / 255.0 + 0.6 * img_np

# Plot
plt.imshow(overlay)
plt.title("Grad-CAM Overlay")
plt.axis("off") # Turn off axis for cleaner image display
plt.show()

import numpy as np

# Convert the pandas Index to a numpy array
features_array = top_features.to_numpy()

# Reshape the array into a 6x6 matrix
matrix_6x6 = features_array.reshape(6, 6)

# Display the 6x6 matrix
print("Top Features arranged as a 6x6 Matrix:")
print(matrix_6x6)

Primary Features: Variance, Magnitue, and Telnet.

Secondary Features: SSH, IRC, and SMTP.

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# --- Input your TP, FP, TN, FN values here ---
tn = 9068 # Example True Negatives
fp = 932   # Example False Positives
fn = 2645  # Example False Negatives
tp = 7355  # Example True Positives

# Create the confusion matrix from the input values
# Standard format is [[TN, FP], [FN, TP]]
cm = np.array([
    [tn, fp],
    [fn, tp]
])

plt.figure(figsize=(6, 5)) # Adjust figure size as needed
ax = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['Predicted Normal', 'Predicted Attack'],
            yticklabels=['Actual Normal', 'Actual Attack'])

# Make annotations bold and increase font size
for text in plt.gca().texts:
    text.set_weight('bold')
    text.set_fontsize(14) # You can change 'large' to a specific number (e.g., 14)

# Make yticklabels bold
for label in ax.get_yticklabels():
    label.set_fontweight('bold')

# Make xticklabels bold
for label in ax.get_xticklabels():
    label.set_fontweight('bold')

plt.xlabel('Predicted Label', fontsize=12, fontweight='bold')
#real time
import pandas as pd
import numpy as np
import tensorflow as tf
from PIL import Image
import os

# --- 1. CONFIGURATION ---
CSV_FILE_PATH = "/content/captured_iot_traffic.csv"
#MODEL_PATH = "/content/your_model.h5"  # Ensure this points to your trained model file
IMAGE_SIZE = 100

# Feature columns MUST match the Scapy logger exactly
FEAT_COLS = [
    'Variance', 'ack_flag_number', 'psh_flag_number', 'rst_count',
    'Header_Length', 'Magnitue', 'TCP', 'UDP', 'Max'
]

# --- GLOBAL SCALING CONSTANTS ---
# These must match the Min/Max of your 'iomtdosnorm.csv' training set
GLOBAL_MIN = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 9.5, 0.0, 0.0, 51.0])
GLOBAL_MAX = np.array([1.0, 1.0, 1.0, 6064.0, 1589090.9, 54.66, 1.0, 1.0, 1514.0])
FEATURE_RANGE = (GLOBAL_MAX - GLOBAL_MIN)
FEATURE_RANGE[FEATURE_RANGE == 0] = 1e-7 # Prevent division by zero

# --- 2. LOAD MODEL & DATA ---


try:
    df = pd.read_csv(CSV_FILE_PATH)
    if df.empty:
        print("[!] CSV is empty. Please run your capture script and attack first.")
        exit()
except Exception as e:
    print(f"[!] Error reading CSV: {e}")
    exit()

# --- 3. IMAGE PREPROCESSING ---

def row_to_image_tensor(row):
    # 1. Apply Global Normalization (Min-Max Scaling)
    # Note: Removed .astype('uint8') here to prevent data loss/wrap-around
    row=row.astype('uint8')
    norm_row = (row - GLOBAL_MIN) / FEATURE_RANGE

    # Clip values to [0, 1] to handle real-time outliers
    norm_row = np.clip(norm_row, 0, 1)

    # 2. Reshape 9 features to 3x3 matrix
    feat_array = norm_row.reshape(3, 3)

    # 3. Scale to 0-255 for pixel intensity
    scaled = feat_array * 255

    # 4. Create RGB image and resize to model's expected input
    img = Image.fromarray(scaled.astype(np.uint8), mode='L').convert('RGB')
    img = img.resize((IMAGE_SIZE, IMAGE_SIZE), Image.NEAREST)

    # 5. Normalize to [0, 1] range for the neural network
    return np.array(img) / 255.0

# Convert all rows in CSV to an image batch
print(f"[*] Processing {len(df)} traffic flows...")
X_test = np.array([row_to_image_tensor(row[FEAT_COLS].values) for _, row in df.iterrows()])



print("[*] Running Vision Transformer inference...")

# Model.predict returns raw logits because of the training configuration
raw_predictions = model.predict(X_test, verbose=1)

# Manual Sigmoid function to handle 'from_logits=True' output
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

# Determine class based on output layer type
if raw_predictions.shape[1] == 1:
    # Binary classification logic
    probs = sigmoid(raw_predictions).flatten()
    print(probs)
    is_attack = (probs > 0.5).astype(int)
else:
    # Multi-class logic (if you updated the model later)
    is_attack = np.argmax(raw_predictions, axis=1)

# --- 5. PRINT FINAL RESULTS ---
attack_count = np.sum(is_attack == 1)
normal_count = np.sum(is_attack == 0)

print("\n" + "="*35)
print("   REAL-TIME EVALUATION RESULTS")
print("="*35)
print(f"Total Traffic Flows: {len(df)}")
print(f"ATTACK Detected:     {attack_count}")
print(f"NORMAL Traffic:      {normal_count}")
print(f"Attack Percentage:   {(attack_count/len(df))*100:.2f}%")
print("="*35)
"""
# --- 4. INFERENCE ---
print("[*] Running Vision Transformer inference...")
predictions = model.predict(X_test, verbose=0)

# Determine class based on output layer type
if predictions.shape[1] == 1:
    # Binary classification with Sigmoid
    probs = predictions.flatten()
    is_attack = (probs > 0.5).astype(int)
else:
    # Multi-class classification with Softmax
    is_attack = np.argmax(predictions, axis=1)

# --- 5. PRINT FINAL RESULTS ---
attack_count = np.sum(is_attack == 1)
normal_count = np.sum(is_attack == 0)

print("\n" + "="*30)
print("  REAL-TIME EVALUATION RESULTS")
print("="*30)
print(f"Total Traffic Flows: {len(df)}")
print(f"Attack Traffic:      {attack_count}")
print(f"Normal Traffic:      {normal_count}")
print("="*30)
"""
plt.ylabel('True Label', fontsize=12, fontweight='bold')
#plt.title('Confusion Matrix', fontsize=14, fontweight='bold')
plt.show()

